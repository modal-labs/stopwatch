id: vllm-qwen
base_config:
  region: us-chicago-1
  llm_server_type: vllm
  data:
    - prompt_tokens=128,output_tokens=1024
    - prompt_tokens=1024,output_tokens=128
    - prompt_tokens=512,output_tokens=512
configs:
  - model: Qwen/Qwen3-235B-A22B
    gpu: H100:8
    llm_server_config:
      - extra_args:
          [
            "--tensor-parallel-size",
            "8",
            "--chat-template",
            "/home/no-system-prompt.jinja",
            "--enable-reasoning",
            "--reasoning-parser",
            "deepseek_r1",
          ]
      - extra_args:
          [
            "--tensor-parallel-size",
            "8",
            "--chat-template",
            "/home/no-system-prompt.jinja",
            "--enable-reasoning",
            "--reasoning-parser",
            "deepseek_r1",
            "--quantization",
            "fp8",
          ]
