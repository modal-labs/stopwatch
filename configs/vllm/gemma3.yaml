id: vllm-gemma3
base_config:
  region: us-chicago-1
  llm_server_type: vllm
  llm_server_config:
    extra_args:
      ["--chat-template", "/home/no-system-prompt.jinja", "--dtype", "bfloat16"]
  data:
    - prompt_tokens=128,output_tokens=1024
    - prompt_tokens=1024,output_tokens=128
    - prompt_tokens=512,output_tokens=512
configs:
  - model: google/gemma-3-4b-it
    gpu: H100
  - model: google/gemma-3-4b-it
    gpu:
      - A10
      - L40S
    region: us-ashburn-1

  - model: google/gemma-3-12b-it
    gpu: H100
  - model: google/gemma-3-27b-it
    gpu: H100
