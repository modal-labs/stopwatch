id: structured-outputs
repeats: 3
base_config:
  model: meta-llama/Llama-3.3-70B-Instruct
  gpu: H100:4
  region: us-chicago-1
  data: prompt_tokens=4096,output_tokens=256
configs:
  - llm_server_type: vllm
    client_config:
      extra_body:
        guided_json:
          properties:
            summary:
              title: Summary
              type: string
          required:
            - summary
          title: Summary
          type: object
    llm_server_config:
      extra_args: ["--tensor-parallel-size", "4", "--max-model-len", "8192"]
  - llm_server_type: sglang
    client_config:
      # SGLang only supports structured outputs for chat completions
      use_chat_completions: true
      extra_body:
        response_format:
          type: json_schema
          json_schema:
            name: Summary
            schema:
              properties:
                sumary:
                  title: Summary
                  type: string
              required:
                - summary
              title: Summary
              type: object
    llm_server_config:
      # The default backend, xgrammar, doesn't seem to work with this schema
      extra_args:
        [
          "--grammar-backend",
          "outlines",
          "--tp",
          "4",
          "--context-length",
          "8192",
        ]
