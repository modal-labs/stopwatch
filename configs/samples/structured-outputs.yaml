id: structured-outputs
base_config:
  model: meta-llama/Llama-3.1-8B-Instruct
  gpu: H100!
  region: us-chicago-1
  data: prompt_tokens=512,output_tokens=128
configs:
  - llm_server_type: vllm
    client_config:
      extra_body:
        guided_json:
          properties:
            summary:
              title: Summary
              type: string
          required:
            - summary
          title: Summary
          type: object
  - llm_server_type: sglang
    client_config:
      # SGLang only supports structured outputs for chat completions
      use_chat_completions: true
      extra_body:
        response_format:
          type: json_schema
          json_schema:
            name: Summary
            schema:
              properties:
                sumary:
                  title: Summary
                  type: string
              required:
                - summary
              title: Summary
              type: object
    llm_server_config:
      # The default backend, xgrammar, doesn't seem to work with this schema
      extra_args: ["--grammar-backend", "outlines"]
      image_kwargs:
        extra_python_packages:
          - outlines
          - transformers==4.53.3
