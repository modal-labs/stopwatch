id: llama-8b-vllm-ootb
repeats: 3
base_config:
  model: meta-llama/Llama-3.1-8B-Instruct
  gpu: H100
  region: us-chicago-1
  data:
    - prompt_tokens=256,generated_tokens=26
    - prompt_tokens=512,generated_tokens=51
    - prompt_tokens=1024,generated_tokens=102
  llm_server_type: vllm
configs:
   - llm_server_config:
       extra_args: []
